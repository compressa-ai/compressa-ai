"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[53],{1109:e=>{e.exports=JSON.parse('{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"docsSidebar":[{"type":"link","label":"Compressa","href":"/ru/","className":"docs_sidebar_index","docId":"docs/index","unlisted":false},{"type":"link","label":"Setup","href":"/ru/docs/setup/","docId":"docs/setup/index","unlisted":false},{"type":"category","label":"Services","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Management API","href":"/ru/docs/services/rest-api","docId":"docs/services/rest-api","unlisted":false}],"href":"/ru/docs/services/"},{"type":"link","label":"Inference","href":"/ru/docs/inference/","docId":"docs/inference/index","unlisted":false},{"type":"link","label":"Finetuning","href":"/ru/docs/finetuning/","docId":"docs/finetuning/index","unlisted":false}],"guidesSidebar":[{"type":"link","label":"Guides","href":"/ru/guides/","className":"guide_sidebar_index","docId":"guides/index","unlisted":false}]},"docs":{"docs/finetuning/index":{"id":"docs/finetuning/index","title":"Finetuning","description":"Compressa provides the feature of low-effort models fine-tuning via LoRA/QLoRA adapters.","sidebar":"docsSidebar"},"docs/index":{"id":"docs/index","title":"Compressa","description":"Fast and advantageous* LLM deployment on your server.","sidebar":"docsSidebar"},"docs/inference/index":{"id":"docs/inference/index","title":"Inference","description":"Once Compressa is set up, the first step to start using a model is to deploy it for inference.","sidebar":"docsSidebar"},"docs/services/index":{"id":"docs/services/index","title":"Services","description":"After the Compressa App is deployed, all components are accessible via the same URL (8080 by default).","sidebar":"docsSidebar"},"docs/services/rest-api":{"id":"docs/services/rest-api","title":"Management API","description":"The Management API is a REST API that allows control over all features.","sidebar":"docsSidebar"},"docs/setup/index":{"id":"docs/setup/index","title":"Setup","description":"Compressa App is distributed as docker containers which are available at Github","sidebar":"docsSidebar"},"guides/index":{"id":"guides/index","title":"Guides","description":"Quickstart","sidebar":"guidesSidebar"},"ru/docs/finetuning/index":{"id":"ru/docs/finetuning/index","title":"Finetuning","description":"Compressa provides the feature of low-effort models fine-tuning via LoRA/QLoRA adapters."},"ru/docs/index":{"id":"ru/docs/index","title":"Compressa","description":"Fast and advantageous* LLM deployment on your server."},"ru/docs/inference/index":{"id":"ru/docs/inference/index","title":"Inference","description":"Once Compressa is set up, the first step to start using a model is to deploy it for inference."},"ru/docs/services/index":{"id":"ru/docs/services/index","title":"Services","description":"After the Compressa App is deployed, all components are accessible via the same URL (8080 by default)."},"ru/docs/services/rest-api":{"id":"ru/docs/services/rest-api","title":"Management API","description":"The Management API is a REST API that allows control over all features."},"ru/docs/setup/index":{"id":"ru/docs/setup/index","title":"Setup","description":"Compressa App is distributed as docker containers which are available at Github"},"ru/guides/index":{"id":"ru/guides/index","title":"Guides","description":"Quickstart"}}}')}}]);