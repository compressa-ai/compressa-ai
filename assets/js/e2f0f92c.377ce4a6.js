"use strict";(self.webpackChunkcompressa_docs=self.webpackChunkcompressa_docs||[]).push([[842],{4620:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>d,contentTitle:()=>o,default:()=>h,frontMatter:()=>r,metadata:()=>a,toc:()=>c});var s=i(4848),t=i(8453);const r={sidebar_position:5},o="Finetuning",a={id:"onprem/LLM_On-Premises/finetuning/index",title:"Finetuning",description:"Compressa provides the feature of low-effort models fine-tuning via LoRA/QLoRA adapters.",source:"@site/docs/onprem/LLM_On-Premises/finetuning/index.md",sourceDirName:"onprem/LLM_On-Premises/finetuning",slug:"/onprem/LLM_On-Premises/finetuning/",permalink:"/onprem/LLM_On-Premises/finetuning/",draft:!1,unlisted:!1,editUrl:"https://github.com/compressa-ai/compressa-ai.github.io/edit/main/docs/onprem/LLM_On-Premises/finetuning/index.md",tags:[],version:"current",sidebarPosition:5,frontMatter:{sidebar_position:5},sidebar:"onpremSidebar",previous:{title:"Quickstart: Mistral-7B On-Premises",permalink:"/onprem/LLM_On-Premises/mistral/"},next:{title:"Quickstart: On-Premises InsightStream",permalink:"/onprem/RAG_On-Premises/insight-stream/"}},d={},c=[{value:"Preparing data",id:"preparing-data",level:2},{value:"Training",id:"training",level:2},{value:"Compressa Finetuning UI",id:"compressa-finetuning-ui",level:3},{value:"Deploy",id:"deploy",level:3}];function l(e){const n={a:"a",br:"br",code:"code",h1:"h1",h2:"h2",h3:"h3",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",...(0,t.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.h1,{id:"finetuning",children:"Finetuning"}),"\n",(0,s.jsx)(n.p,{children:"Compressa provides the feature of low-effort models fine-tuning via LoRA/QLoRA adapters."}),"\n",(0,s.jsx)(n.p,{children:"Fine-tuning allows to increase quality for business cases, focus model on some topic or introduce format to the output data."}),"\n",(0,s.jsx)(n.h2,{id:"preparing-data",children:"Preparing data"}),"\n",(0,s.jsx)(n.p,{children:"Compressa allows to fine-tune models on chat data.\nTo start the process you should:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"Prepare conversation examples"}),"\n",(0,s.jsxs)(n.li,{children:["Format them into ",(0,s.jsx)(n.a,{href:"https://jsonlines.org/",children:"JSON Lines"})," format with the next content on each line:"]}),"\n"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:'{\n    "messages": [\n        {\n            "role": "user",\n            "content": "<USER MESSAGE 1>"\n        },\n        {\n            "role": "bot",\n            "content": " <BOT\'S RESPONSE>"\n        },\n        {\n            "role": "user",\n            "content": "<USER MESSAGE 2>"\n        },\n        {\n            "role": "bot",\n            "content": " <BOT\'S RESPONSE2>"\n        },\n    ]\n}\n'})}),"\n",(0,s.jsxs)(n.p,{children:["Each dialog can have any number of messages.",(0,s.jsx)(n.br,{}),"\n","Dataset should have at least 100 samples."]}),"\n",(0,s.jsx)(n.h2,{id:"training",children:"Training"}),"\n",(0,s.jsxs)(n.p,{children:["When data is prepared you can start training in Compressa Finetuning UI or with REST API.",(0,s.jsx)(n.br,{}),"\n","Documentation for REST API can be found at Management API documentation ",(0,s.jsx)(n.a,{href:"/onprem/LLM_On-Premises/services/rest-api/",children:"page"}),"."]}),"\n",(0,s.jsx)(n.h3,{id:"compressa-finetuning-ui",children:"Compressa Finetuning UI"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"URL"}),": ",(0,s.jsx)(n.code,{children:"http://localhost:8080/finetune/"})]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:"Fine-Tune UI",src:i(6687).A+"",width:"2704",height:"1698"})}),"\n",(0,s.jsx)(n.p,{children:"To finetune model using UI you should:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"Select a model in the left panel"}),"\n",(0,s.jsx)(n.li,{children:"Fill-in the name of your finetune"}),"\n",(0,s.jsxs)(n.li,{children:["Upload ",(0,s.jsx)(n.code,{children:"jsonl"})," file to the form"]}),"\n",(0,s.jsxs)(n.li,{children:["Click the ",(0,s.jsx)(n.strong,{children:"Finetune"})," button"]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["Then you can track training process in ",(0,s.jsx)(n.a,{href:"https://github.com/aimhubio/aim",children:"AIM"})," dashboard.",(0,s.jsx)(n.br,{}),"\n","Dashboard can be opened by clicking Training Dashboard.\n",(0,s.jsx)(n.img,{alt:"Training Dashboard",src:i(6720).A+"",width:"2714",height:"1702"})]}),"\n",(0,s.jsxs)(n.p,{children:["The dashboard allows to choose run by the provided name and see metrics:\n",(0,s.jsx)(n.img,{alt:"Training Dashboard",src:i(1674).A+"",width:"2858",height:"1770"})]}),"\n",(0,s.jsx)(n.h3,{id:"deploy",children:"Deploy"}),"\n",(0,s.jsxs)(n.p,{children:["When training process is finished, adapter can be deployed in Compressa for inference.",(0,s.jsx)(n.br,{}),"\n","The full instruction for deployment can be found at ",(0,s.jsx)(n.a,{href:"/onprem/LLM_On-Premises/inference/",children:"page"}),"."]})]})}function h(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(l,{...e})}):l(e)}},1674:(e,n,i)=>{i.d(n,{A:()=>s});const s=i.p+"assets/images/aim-metrics-071e1b428c59dd1f300899a495f778c5.png"},6687:(e,n,i)=>{i.d(n,{A:()=>s});const s=i.p+"assets/images/finetune-272560fe59b36eb751e0d5c92cacd5e7.png"},6720:(e,n,i)=>{i.d(n,{A:()=>s});const s=i.p+"assets/images/training-dashboard-9d0e87da0b7d90d5c8404d052358932c.png"},8453:(e,n,i)=>{i.d(n,{R:()=>o,x:()=>a});var s=i(6540);const t={},r=s.createContext(t);function o(e){const n=s.useContext(r);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:o(e.components),s.createElement(r.Provider,{value:n},e.children)}}}]);