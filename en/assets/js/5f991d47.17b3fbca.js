"use strict";(self.webpackChunkcompressa_docs=self.webpackChunkcompressa_docs||[]).push([[972],{4893:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>o,default:()=>h,frontMatter:()=>r,metadata:()=>i,toc:()=>l});var s=t(4848),a=t(8453);const r={sidebar_position:1},o="RAG example",i={id:"guides/langchain_rag/index",title:"RAG example",description:"RAG (Retrieval Augmented Generation) is a method of working with large language models when the request context",source:"@site/docs/guides/langchain_rag/index.md",sourceDirName:"guides/langchain_rag",slug:"/guides/langchain_rag/",permalink:"/en/guides/langchain_rag/",draft:!1,unlisted:!1,editUrl:"https://github.com/compressa-ai/compressa-ai.github.io/edit/main/docs/guides/langchain_rag/index.md",tags:[],version:"current",sidebarPosition:1,frontMatter:{sidebar_position:1},sidebar:"guidesSidebar",previous:{title:"Basic intro to semantic search",permalink:"/en/guides/langchain_basic_semantic_search/"}},c={},l=[];function d(e){const n={a:"a",code:"code",h1:"h1",li:"li",p:"p",pre:"pre",ul:"ul",...(0,a.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.h1,{id:"rag-example",children:"RAG example"}),"\n",(0,s.jsx)(n.p,{children:"RAG (Retrieval Augmented Generation) is a method of working with large language models when the request context\nadditional information is programmatically added to the language model, on the basis of which the language model\ncan give the user a more complete and accurate answer."}),"\n",(0,s.jsx)(n.p,{children:"First, you need to install the package"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"pip install langchain-compressa\n"})}),"\n",(0,s.jsxs)(n.p,{children:["Next, you need to get API key after registration ",(0,s.jsx)(n.a,{href:"https://compressa.ai/form",children:"registration"}),"."]}),"\n",(0,s.jsx)(n.p,{children:"Make sure to set the following environment variable:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"COMPRESSA_API_KEY"}),"\n"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'import os\nos.environ["COMPRESSA_API_KEY"] = "your_key_here"\n'})}),"\n",(0,s.jsx)(n.p,{children:"And after that you can start"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"import os\nfrom langchain_compressa import CompressaEmbeddings, ChatCompressa, CompressaRerank\nfrom langchain_core.documents import Document\nfrom langchain.chains.combine_documents import create_stuff_documents_chain\nfrom langchain.chains import create_retrieval_chain\nfrom langchain.retrievers.contextual_compression import ContextualCompressionRetriever\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langchain_text_splitters import RecursiveCharacterTextSplitter\nfrom langchain_community.document_loaders import WebBaseLoader\nfrom langchain_chroma import Chroma\n\nCOMPRESSA_API_KEY = os.getenv('COMPRESSA_API_KEY')\n"})}),"\n",(0,s.jsx)(n.p,{children:"let's define llm and embedding"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"compressa_embedding = CompressaEmbeddings(api_key=COMPRESSA_API_KEY)\nllm = ChatCompressa(api_key=COMPRESSA_API_KEY)\n"})}),"\n",(0,s.jsx)(n.p,{children:"let's define a document loader and get langchain documents.\nany of the available loaders can be used here."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'loader = WebBaseLoader("https://docs.smith.langchain.com/overview")\ndocs = loader.load()\n'})}),"\n",(0,s.jsx)(n.p,{children:"define text_splitter and split documents into chunks"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"text_splitter = RecursiveCharacterTextSplitter(\n    chunk_size=500, chunk_overlap=100, add_start_index=True\n)\nall_splits = text_splitter.split_documents(docs)\n"})}),"\n",(0,s.jsx)(n.p,{children:"load document chunks into vectorstore and define retriever"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'vectorstore = Chroma.from_documents(documents=all_splits, embedding=compressa_embedding)\nretriever = vectorstore.as_retriever(search_type="similarity", search_kwargs={"k": 5})\n'})}),"\n",(0,s.jsx)(n.p,{children:"define reranker to use after retriever in chains"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"compressor = CompressaRerank(api_key=COMPRESSA_API_KEY)\ncompression_retriever = ContextualCompressionRetriever(\n    base_compressor=compressor, base_retriever=retriever\n)\n"})}),"\n",(0,s.jsx)(n.p,{children:"let's define a Prompt to get answers to user questions based only on context and not on previous knowledge"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'system_template = f"""You are an assistant for question-answering tasks. \nUse the following pieces of retrieved context to answer the question. \nIf you don\'t know the answer, just say that you don\'t know. \nUse three sentences maximum and keep the answer concise."""\n\nqa_prompt = ChatPromptTemplate.from_messages([\n    ("system", system_template),\n    ("human", """Context information:\n\n        {context}\n        \n        Query: {input}\t\t\n    """),\n])\n'})}),"\n",(0,s.jsx)(n.p,{children:"let's set 2 chains: to retrieve and rerank documents on the question and to get the final answer"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)\n\nrag_chain = create_retrieval_chain(compression_retriever, question_answer_chain)\n"})}),"\n",(0,s.jsx)(n.p,{children:"now we can ask a question"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'answ = rag_chain.invoke({"input": "how can langsmith help with testing?"})\nprint(answ["answer"])\n'})}),"\n",(0,s.jsx)(n.p,{children:"Note: to work better with Russian sources, prompt also needs to be written in Russian"})]})}function h(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>o,x:()=>i});var s=t(6540);const a={},r=s.createContext(a);function o(e){const n=s.useContext(r);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function i(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:o(e.components),s.createElement(r.Provider,{value:n},e.children)}}}]);